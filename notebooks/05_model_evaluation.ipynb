{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699d7291",
   "metadata": {},
   "source": [
    "# 05 - Model Evaluation\n",
    "\n",
    "This notebook evaluates model performance and identifies areas for improvement.\n",
    "\n",
    "## Objectives:\n",
    "- Calculate performance metrics\n",
    "- Generate confusion matrix and classification reports\n",
    "- Visualize predictions vs actual values\n",
    "- Residual analysis\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('../models/best_model.pkl')\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# X_test = ...\n",
    "# y_test = ...\n",
    "# \n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2656f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# \n",
    "# print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "# print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "# print(f\"RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "# plt.xlabel('Actual Values')\n",
    "# plt.ylabel('Predicted Values')\n",
    "# plt.title('Predictions vs Actual Values')\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4356fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# if hasattr(model, 'feature_importances_'):\n",
    "#     feature_importance = pd.DataFrame({\n",
    "#         'feature': X_test.columns,\n",
    "#         'importance': model.feature_importances_\n",
    "#     }).sort_values('importance', ascending=False)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.barplot(data=feature_importance.head(20), x='importance', y='feature')\n",
    "#     plt.title('Top 20 Feature Importance')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "# residuals = y_test - y_pred\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(residuals, bins=30, edgecolor='black')\n",
    "# plt.xlabel('Residuals')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Residuals')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
